import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
import docx
import pandas as pd
from youtube_transcript_api import YouTubeTranscriptApi
from bs4 import BeautifulSoup
import requests
import tempfile
import os
from PIL import Image # Nueva librer√≠a para im√°genes
from datetime import date

# --- 1. CONFIGURACI√ìN E IDENTIDAD ---
st.set_page_config(page_title="IkigAI V1.9 - Visi√≥n Multimodal", page_icon="üß¨", layout="wide")

if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("üîë Configure su API Key en st.secrets.")
    st.stop()

# Diccionario de Roles Completo (Se mantienen todos los previos)
ROLES = {
    "Coach de Alto Desempe√±o": "Productividad, ROI cognitivo y mentalidad de abundancia.",
    "Director Centro Telemedicina": "Estratega en Salud Digital e IA. Innovaci√≥n y Hospital Virtual.",
    "Vicedecano Acad√©mico": "Gesti√≥n UNAL, normativa y liderazgo institucional.",
    "Director de UCI": "Rigor cl√≠nico, seguridad del paciente y datos en cuidado cr√≠tico.",
    "Consultor Salud Digital": "Estrategia BID/MinSalud. Territorio e interculturalidad.",
    "Profesor Universitario": "Pedagog√≠a disruptiva y mentor√≠a m√©dica.",
    "Estratega de Trading": "An√°lisis t√©cnico, gesti√≥n de riesgo y psicolog√≠a de mercado."
}

# --- 2. FUNCIONES DE LECTURA (PDF, DOCX, EXCEL, WEB, YT) ---
# (Se mantienen las funciones de lectura previas...)

# --- 3. L√ìGICA DE MEMORIA ---
if "biblioteca" not in st.session_state:
    st.session_state.biblioteca = {rol: "" for rol in ROLES.keys()}
if "messages" not in st.session_state: st.session_state.messages = []
if "temp_image" not in st.session_state: st.session_state.temp_image = None

# --- 4. BARRA LATERAL: CONECTORES DE LECTURA ---
with st.sidebar:
    st.title("üß¨ IkigAI Engine")
    rol_activo = st.selectbox("Cambiar Rol Estrat√©gico:", list(ROLES.keys()))
    
    st.divider()
    st.subheader(f"üîå Fuentes para {rol_activo}")
    
    tab_files, tab_links, tab_vision = st.tabs(["üìÑ Archivos", "üîó Links", "üëÅÔ∏è Visi√≥n"])
    
    with tab_files:
        up_files = st.file_uploader("Cargar PDF, Word, Excel:", type=['pdf', 'docx', 'xlsx'], accept_multiple_files=True)
        if st.button("üß† Leer Documentos"):
            # (L√≥gica de lectura de archivos previa...)
            st.success("Documentos le√≠dos.")

    with tab_links:
        url_w = st.text_input("URL Web:")
        url_y = st.text_input("URL YouTube:")
        if st.button("üåê Leer Links"):
            # (L√≥gica de lectura de links previa...)
            st.success("Fuentes externas le√≠das.")

    with tab_vision:
        img_file = st.file_uploader("Subir imagen (JPG, PNG, captura):", type=['jpg', 'jpeg', 'png'])
        if img_file:
            st.session_state.temp_image = Image.open(img_file)
            st.image(st.session_state.temp_image, caption="Imagen cargada para an√°lisis", use_container_width=True)

# --- 5. PANEL CENTRAL ---
st.header(f"IkigAI: {rol_activo}")

# Chat Multimodal
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

if prompt := st.chat_input("¬øQu√© analizamos hoy, Doctor?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)

    with st.chat_message("assistant"):
        model = genai.GenerativeModel('gemini-1.5-pro')
        
        # Construcci√≥n del mensaje multimodal
        system_p = f"""
        IDENTIDAD: IkigAI en modo {rol_activo}. {ROLES[rol_activo]}
        CONTENIDO LE√çDO PREVIAMENTE: {st.session_state.biblioteca[rol_activo][:500000]}
        INSTRUCCI√ìN: Analiza el prompt y, si hay una imagen, relacionala con el contexto de tu rol.
        Estilo directo, cl√≠nico y ejecutivo. Sin clich√©s.
        """
        
        inputs = [system_p, prompt]
        if st.session_state.temp_image:
            inputs.append(st.session_state.temp_image)
        
        res = model.generate_content(inputs)
        st.markdown(res.text)
        st.session_state.messages.append({"role": "assistant", "content": res.text})
        
        # Limpiamos la imagen tras el an√°lisis para la pr√≥xima consulta
        st.session_state.temp_image = None
